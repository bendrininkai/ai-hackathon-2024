{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting population in Vilnius districts by age group and gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jonas Vitkauskas | \n",
    "Paulina Udes |\n",
    "Donatas GoÅ¡tautas | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import Dropdown, VBox, HBox, Button, Output\n",
    "from IPython.display import display\n",
    "import logging\n",
    "import warnings\n",
    "import contextlib\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting rid of warning and logging messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress logging messages from cmdstanpy\n",
    "logger = logging.getLogger('cmdstanpy')\n",
    "logger.setLevel(logging.ERROR)\n",
    "for handler in logger.handlers:\n",
    "    handler.setLevel(logging.ERROR)\n",
    "\n",
    "# Suppress SettingWithCopyWarning\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context manager to suppress logging\n",
    "@contextlib.contextmanager\n",
    "def suppress_logging():\n",
    "    logging.disable(logging.CRITICAL)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        logging.disable(logging.NOTSET)\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_and_preprocess(train_file_path, test_file_path):\n",
    "    train_data = pd.read_csv(train_file_path)\n",
    "    test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "    train_data['as_of_date_id'] = train_data['as_of_date_id'].astype(int)\n",
    "    train_data['age_bin_id'] = train_data['age_bin_id'].astype(str)\n",
    "    train_data['gender_id'] = train_data['gender_id'].astype(str)\n",
    "    train_data['district_id'] = train_data['district_id'].astype(str)\n",
    "\n",
    "    test_data['as_of_date_id'] = test_data['as_of_date_id'].astype(int)\n",
    "    test_data['age_bin_id'] = test_data['age_bin_id'].astype(str)\n",
    "    test_data['gender_id'] = test_data['gender_id'].astype(str)\n",
    "    test_data['district_id'] = test_data['district_id'].astype(str)\n",
    "\n",
    "    # Smoothing time period 76\n",
    "    for age_bin in train_data['age_bin_id'].unique():\n",
    "        for gender in train_data['gender_id'].unique():\n",
    "            for district in train_data['district_id'].unique():\n",
    "                mask = (train_data['age_bin_id'] == age_bin) & (train_data['gender_id'] == gender) & (train_data['district_id'] == district)\n",
    "                count_75 = train_data.loc[mask & (train_data['as_of_date_id'] == 75), 'count'].values\n",
    "                count_77 = train_data.loc[mask & (train_data['as_of_date_id'] == 77), 'count'].values\n",
    "                if len(count_75) > 0 and len(count_77) > 0:\n",
    "                    avg_count = (count_75[0] + count_77[0]) / 2\n",
    "                    train_data.loc[mask & (train_data['as_of_date_id'] == 76), 'count'] = avg_count\n",
    "\n",
    "    # Filter train_data to start from as_of_date_id 70\n",
    "    train_data = train_data[train_data['as_of_date_id'] >= 70].reset_index(drop=True)\n",
    "\n",
    "    # Assume start date and convert 'as_of_date_id' to datetime\n",
    "    start_date = pd.to_datetime('2000-01-01')\n",
    "    train_data['ds'] = start_date + pd.to_timedelta(train_data['as_of_date_id'], unit='D')\n",
    "    test_data['ds'] = start_date + pd.to_timedelta(test_data['as_of_date_id'], unit='D')\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Function to normalize data\n",
    "def normalize_data(df, column):\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    df[column] = (df[column] - mean) / std\n",
    "    return mean, std\n",
    "\n",
    "# Function to denormalize data\n",
    "def denormalize_data(df, column, mean, std):\n",
    "    df[column] = df[column] * std + mean\n",
    "    return df\n",
    "\n",
    "# Function to train models using Prophet\n",
    "def train_models(train_data, specific_hyperparams=None):\n",
    "    models = {}\n",
    "    unique_combinations = train_data[['district_id', 'age_bin_id', 'gender_id']].drop_duplicates()\n",
    "\n",
    "    for _, row in unique_combinations.iterrows():\n",
    "        district, age_bin, gender = row['district_id'], row['age_bin_id'], row['gender_id']\n",
    "        mask = (train_data['district_id'] == district) & (train_data['age_bin_id'] == age_bin) & (train_data['gender_id'] == gender)\n",
    "        subset_data = train_data[mask]\n",
    "\n",
    "        # Normalize the data\n",
    "        mean, std = normalize_data(subset_data, 'count')\n",
    "        \n",
    "        subset_data = subset_data.rename(columns={'ds': 'ds', 'count': 'y'})\n",
    "\n",
    "        # Use specific hyperparameters if provided for the specific case\n",
    "        if specific_hyperparams and (district, age_bin, gender) in specific_hyperparams:\n",
    "            hyperparams = specific_hyperparams[(district, age_bin, gender)]\n",
    "            model = Prophet(\n",
    "                yearly_seasonality=hyperparams.get('yearly_seasonality', 'auto'),\n",
    "                changepoint_prior_scale=hyperparams.get('changepoint_prior_scale', 0.4),\n",
    "                seasonality_prior_scale=hyperparams.get('seasonality_prior_scale', 10),\n",
    "                changepoint_range=hyperparams.get('changepoint_range', 0.7)\n",
    "            )\n",
    "            model.add_seasonality(\n",
    "                name='12-period',\n",
    "                period=12,\n",
    "                fourier_order=hyperparams.get('fourier_order', 10)\n",
    "            )\n",
    "        else:\n",
    "            model = Prophet(\n",
    "                yearly_seasonality='auto',  # Enable yearly seasonality\n",
    "                changepoint_prior_scale=0.4,  # Control trend flexibility\n",
    "                seasonality_prior_scale=10,  # Control seasonality flexibility\n",
    "                changepoint_range=0.7  # Allow more flexibility for trend changes\n",
    "            )\n",
    "            model.add_seasonality(\n",
    "                name='12-period',\n",
    "                period=12,\n",
    "                fourier_order=10 # Seasonal sharpness\n",
    "            )\n",
    "\n",
    "        with suppress_logging():\n",
    "            model.fit(subset_data[['ds', 'y']])\n",
    "        \n",
    "        models[(district, age_bin, gender)] = (model, mean, std)\n",
    "    return models\n",
    "\n",
    "# Function to make predictions\n",
    "def make_predictions(models, test_data):\n",
    "    predictions = []\n",
    "\n",
    "    unique_combinations = test_data[['district_id', 'age_bin_id', 'gender_id']].drop_duplicates()\n",
    "\n",
    "    for _, row in unique_combinations.iterrows():\n",
    "        district, age_bin, gender = row['district_id'], row['age_bin_id'], row['gender_id']\n",
    "        model, mean, std = models[(district, age_bin, gender)]\n",
    "        mask_test = (test_data['district_id'] == district) & (test_data['age_bin_id'] == age_bin) & (test_data['gender_id'] == gender)\n",
    "        subset_test_data = test_data[mask_test]\n",
    "\n",
    "        future = subset_test_data[['ds']]\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        # Denormalize the predictions\n",
    "        forecast['yhat'] = forecast['yhat'] * std + mean\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "            subset_test_data['Prediction'] = forecast['yhat'].values\n",
    "            subset_test_data['Prediction'] = subset_test_data['Prediction'].iloc[::-1].values\n",
    "\n",
    "        predictions.append(subset_test_data[['ID', 'district_id', 'age_bin_id', 'gender_id', 'as_of_date_id', 'Prediction']])\n",
    "    \n",
    "    return pd.concat(predictions, ignore_index=True)\n",
    "\n",
    "# Function to plot results\n",
    "def plot_results(train_data, predictions):\n",
    "    train_plot_df = train_data.groupby('as_of_date_id')['count'].sum().reset_index()\n",
    "    fig_train = px.line(\n",
    "        train_plot_df, x='as_of_date_id', y='count',\n",
    "        title='Sum of Population per Period of Time (Training Data)',\n",
    "        labels={'as_of_date_id': 'Time Period', 'count': 'Total Population'},\n",
    "        markers=True)\n",
    "    \n",
    "    test_plot_df = predictions.groupby('as_of_date_id')['Prediction'].sum().reset_index()\n",
    "    fig_test = px.line(\n",
    "        test_plot_df, x='as_of_date_id', y='Prediction',\n",
    "        title='Sum of Population per Period of Time (Test Predictions)',\n",
    "        labels={'as_of_date_id': 'Time Period', 'Prediction': 'Total Predicted Population'},\n",
    "        markers=True)\n",
    "    \n",
    "    # Change the color of the prediction line\n",
    "    fig_test.data[0].line.color = 'red'\n",
    "    \n",
    "    fig_train.add_trace(fig_test.data[0])\n",
    "    fig_train.update_layout(\n",
    "        title='Population Count per Period of Time (Training Data and Test Predictions)',\n",
    "        xaxis_title='Time Period',\n",
    "        yaxis_title='Population Count',\n",
    "        legend_title='Dataset')\n",
    "    \n",
    "    # Calculate the min and max values for y-axis\n",
    "    all_y_values = pd.concat([train_plot_df['count'], test_plot_df['Prediction']])\n",
    "    y_min = all_y_values.min() * 0.99\n",
    "    y_max = all_y_values.max() * 1.01\n",
    "\n",
    "    # Add vertical lines for specified time periods\n",
    "    vertical_lines = [82, 94, 106, 118]\n",
    "    for period in vertical_lines:\n",
    "        fig_train.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=period,\n",
    "            y0=y_min,\n",
    "            x1=period,\n",
    "            y1=y_max,\n",
    "            line=dict(color=\"Green\", width=2, dash=\"dash\")\n",
    "        )\n",
    "    \n",
    "    fig_train.show()\n",
    "\n",
    "\n",
    "# Function to plot results for a specific combination\n",
    "def plot_individual_results(district, age_bin, gender):\n",
    "    train_subset = train_data[(train_data['district_id'] == district) & \n",
    "                              (train_data['age_bin_id'] == age_bin) & \n",
    "                              (train_data['gender_id'] == gender)]\n",
    "    \n",
    "    pred_subset = predictions[(predictions['district_id'] == district) & \n",
    "                              (predictions['age_bin_id'] == age_bin) & \n",
    "                              (predictions['gender_id'] == gender)]\n",
    "    \n",
    "    # Fit a linear regression to the training data\n",
    "    X_train = train_subset['as_of_date_id'].values.reshape(-1, 1)\n",
    "    y_train = train_subset['count'].values\n",
    "    linear_regressor = LinearRegression()\n",
    "    linear_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Create a range for the trend line from the start of training to the end of predictions\n",
    "    start_train = train_subset['as_of_date_id'].min()\n",
    "    end_pred = pred_subset['as_of_date_id'].max()\n",
    "    X_trend = np.arange(start_train, end_pred + 1).reshape(-1, 1)\n",
    "    y_trend = linear_regressor.predict(X_trend)\n",
    "    \n",
    "    # Create a dataframe for the trend line\n",
    "    trend_df = pd.DataFrame({\n",
    "        'as_of_date_id': X_trend.flatten(),\n",
    "        'trend': y_trend\n",
    "    })\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add training data\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=train_subset['as_of_date_id'], \n",
    "        y=train_subset['count'], \n",
    "        mode='lines+markers', \n",
    "        name='Training Data',\n",
    "        line=dict(color='blue')\n",
    "    ))\n",
    "    \n",
    "    # Add prediction data\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pred_subset['as_of_date_id'], \n",
    "        y=pred_subset['Prediction'], \n",
    "        mode='lines+markers', \n",
    "        name='Predictions',\n",
    "        line=dict(color='red')\n",
    "    ))\n",
    "\n",
    "    # Add trend line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=trend_df['as_of_date_id'], \n",
    "        y=trend_df['trend'], \n",
    "        mode='lines', \n",
    "        name='Trend Line',\n",
    "        line=dict(color='rgba(0, 0, 0, 0.5)', width=1, dash=\"dash\"),\n",
    "        showlegend=True\n",
    "    ))\n",
    "\n",
    "    # Calculate the min and max values for y-axis\n",
    "    all_y_values = pd.concat([train_subset['count'], pred_subset['Prediction'], trend_df['trend']])\n",
    "    y_min = all_y_values.min() * 0.99\n",
    "    y_max = all_y_values.max() * 1.01\n",
    "\n",
    "    # Add vertical lines for specified time periods\n",
    "    vertical_lines = [82, 94, 106, 118]\n",
    "    for period in vertical_lines:\n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=period,\n",
    "            y0=y_min,\n",
    "            x1=period,\n",
    "            y1=y_max,\n",
    "            line=dict(color=\"Green\", width=2, dash=\"dash\")\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'Population Count per Period of Time (District: {district}, Age Bin: {age_bin}, Gender: {gender})',\n",
    "        xaxis_title='Time Period',\n",
    "        yaxis_title='Population Count',\n",
    "        legend_title='Dataset',\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading data/training model/predicting/plotting general overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "train_file_path = 'data/train.csv'\n",
    "test_file_path = 'data/test.csv'\n",
    "\n",
    "# Load and preprocess data\n",
    "train_data, test_data = load_and_preprocess(train_file_path, test_file_path)\n",
    "\n",
    "# Specify sets that needed to be changed from general model\n",
    "specific_hyperparams = {\n",
    "    ('0', '1', '0'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.6, 'seasonality_prior_scale': 20, 'changepoint_range': 0.7, 'fourier_order': 10},\n",
    "    ('0', '4', '0'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.3, 'seasonality_prior_scale': 5, 'changepoint_range': 0.9, 'fourier_order': 10},\n",
    "    ('0', '5', '0'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.5, 'seasonality_prior_scale': 15, 'changepoint_range': 0.5, 'fourier_order': 15},\n",
    "    ('0', '5', '1'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.5, 'seasonality_prior_scale': 10, 'changepoint_range': 0.5, 'fourier_order': 10},\n",
    "\n",
    "    ('1', '1', '1'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.1, 'seasonality_prior_scale': 15, 'changepoint_range': 0.95, 'fourier_order': 5},\n",
    "    ('1', '4', '0'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.3, 'seasonality_prior_scale': 10, 'changepoint_range': 0.95, 'fourier_order': 7},\n",
    "    ('1', '4', '1'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.7, 'seasonality_prior_scale': 5, 'changepoint_range': 0.9, 'fourier_order': 10},\n",
    "\n",
    "    ('2', '2', '0'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.001, 'seasonality_prior_scale': 1, 'changepoint_range': 0.8, 'fourier_order': 1},\n",
    "    ('2', '2', '1'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.3, 'seasonality_prior_scale': 5, 'changepoint_range': 0.95, 'fourier_order': 1},\n",
    "    ('2', '5', '0'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.7, 'seasonality_prior_scale': 10, 'changepoint_range': 0.95, 'fourier_order': 20},\n",
    "\n",
    "    ('3', '1', '0'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.1, 'seasonality_prior_scale': 5, 'changepoint_range': 0.5, 'fourier_order': 7},\n",
    "\n",
    "    ('5', '4', '1'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 1.0, 'seasonality_prior_scale': 15, 'changepoint_range': 0.95, 'fourier_order': 15},\n",
    "\n",
    "    ('6', '4', '1'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.3, 'seasonality_prior_scale': 1, 'changepoint_range': 0.95, 'fourier_order': 7},\n",
    "\n",
    "    ('7', '4', '1'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.05, 'seasonality_prior_scale': 5, 'changepoint_range': 0.95, 'fourier_order': 10},\n",
    "\n",
    "    ('8', '4', '0'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.4, 'seasonality_prior_scale': 1, 'changepoint_range': 0.95, 'fourier_order': 5},\n",
    "    ('8', '4', '1'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.05, 'seasonality_prior_scale': 20, 'changepoint_range': 0.8, 'fourier_order': 5},\n",
    "\n",
    "    ('9', '3', '1'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.5, 'seasonality_prior_scale': 5, 'changepoint_range': 0.9, 'fourier_order': 5},\n",
    "\n",
    "    ('12', '4', '0'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.7, 'seasonality_prior_scale': 5, 'changepoint_range': 0.5, 'fourier_order': 5},\n",
    "\n",
    "    ('15', '4', '1'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.3, 'seasonality_prior_scale': 15, 'changepoint_range': 0.7, 'fourier_order': 1},\n",
    "\n",
    "    ('16', '3', '1'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 1.0, 'seasonality_prior_scale': 1, 'changepoint_range': 0.95, 'fourier_order': 1},\n",
    "\n",
    "    ('17', '4', '1'): {'yearly_seasonality': 'auto', 'changepoint_prior_scale': 0.4, 'seasonality_prior_scale': 1, 'changepoint_range': 0.9, 'fourier_order': 1},\n",
    "}\n",
    "\n",
    "# Train models for each combination of district, age_bin, and gender using Prophet\n",
    "models = train_models(train_data, specific_hyperparams)\n",
    "\n",
    "# Make predictions using the trained models\n",
    "predictions = make_predictions(models, test_data)\n",
    "# Adjusted prediction level, fixing model overfitting\n",
    "predictions['Prediction'] = predictions['Prediction'] * 1.0035\n",
    "\n",
    "# Plot combined results\n",
    "plot_results(train_data, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting overview case by case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dropdown for each combination to view individual plots\n",
    "unique_combinations = train_data[['district_id', 'age_bin_id', 'gender_id']].drop_duplicates()\n",
    "\n",
    "# Convert district_id to integers for correct sorting, then sort by district_id, age_bin_id, and gender_id\n",
    "unique_combinations['district_id_int'] = unique_combinations['district_id'].astype(int)\n",
    "unique_combinations = unique_combinations.sort_values(by=['district_id_int', 'age_bin_id', 'gender_id'])\n",
    "\n",
    "# Create the options for the dropdown\n",
    "options = [(f'District: {row[\"district_id\"]}, Age Bin: {row[\"age_bin_id\"]}, Gender: {row[\"gender_id\"]}', \n",
    "            (row[\"district_id\"], row[\"age_bin_id\"], row[\"gender_id\"])) for _, row in unique_combinations.iterrows()]\n",
    "\n",
    "# Drop the temporary integer column\n",
    "unique_combinations = unique_combinations.drop(columns=['district_id_int'])\n",
    "\n",
    "\n",
    "# Initialize the figure widget\n",
    "fig = go.FigureWidget()\n",
    "\n",
    "def update_plot(change):\n",
    "    district, age_bin, gender = change['new']\n",
    "    new_fig = plot_individual_results(district, age_bin, gender)\n",
    "    \n",
    "    with fig.batch_update():\n",
    "        fig.data = []\n",
    "        for trace in new_fig.data:\n",
    "            fig.add_trace(trace)\n",
    "        fig.layout = new_fig.layout\n",
    "\n",
    "# Create the dropdown widget\n",
    "dropdown = Dropdown(options=options, description='Select Group:')\n",
    "dropdown.observe(update_plot, names='value')\n",
    "\n",
    "# Create 'Back' and 'Next' buttons\n",
    "back_button = Button(description='Back')\n",
    "next_button = Button(description='Next')\n",
    "\n",
    "# Function to handle 'Back' button click\n",
    "def on_back_button_clicked(b):\n",
    "    current_index = [i[1] for i in options].index(dropdown.value)\n",
    "    if current_index > 0:\n",
    "        dropdown.value = options[current_index - 1][1]\n",
    "\n",
    "# Function to handle 'Next' button click\n",
    "def on_next_button_clicked(b):\n",
    "    current_index = [i[1] for i in options].index(dropdown.value)\n",
    "    if current_index < len(options) - 1:\n",
    "        dropdown.value = options[current_index + 1][1]\n",
    "\n",
    "back_button.on_click(on_back_button_clicked)\n",
    "next_button.on_click(on_next_button_clicked)\n",
    "\n",
    "# Display the dropdown, buttons, and the plot output\n",
    "display(VBox([HBox([back_button, next_button, dropdown]), fig]))\n",
    "\n",
    "# Initialize with the first combination\n",
    "dropdown.value = options[0][1]\n",
    "update_plot({'new': options[0][1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to 'output.csv'\n",
    "output = predictions[['ID', 'Prediction']].rename(columns={'Prediction': 'count'}).sort_values(by='ID')\n",
    "output.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

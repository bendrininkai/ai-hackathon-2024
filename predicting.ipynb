{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting population in Vilnius districts by age group and gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jonas Vitkauskas\n",
    "Paulina Udes\n",
    "Donatas GoÅ¡tautas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from ipywidgets import Dropdown, VBox, HBox, Button, Output\n",
    "from IPython.display import display\n",
    "import logging\n",
    "import warnings\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting rid of warning and logging messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress logging messages from cmdstanpy\n",
    "logger = logging.getLogger('cmdstanpy')\n",
    "logger.setLevel(logging.ERROR)\n",
    "for handler in logger.handlers:\n",
    "    handler.setLevel(logging.ERROR)\n",
    "\n",
    "# Suppress SettingWithCopyWarning\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context manager to suppress logging\n",
    "@contextlib.contextmanager\n",
    "def suppress_logging():\n",
    "    logging.disable(logging.CRITICAL)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        logging.disable(logging.NOTSET)\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_and_preprocess(train_file_path, test_file_path):\n",
    "    train_data = pd.read_csv(train_file_path)\n",
    "    test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "    train_data['as_of_date_id'] = train_data['as_of_date_id'].astype(int)\n",
    "    train_data['age_bin_id'] = train_data['age_bin_id'].astype(str)\n",
    "    train_data['gender_id'] = train_data['gender_id'].astype(str)\n",
    "    train_data['district_id'] = train_data['district_id'].astype(str)\n",
    "\n",
    "    test_data['as_of_date_id'] = test_data['as_of_date_id'].astype(int)\n",
    "    test_data['age_bin_id'] = test_data['age_bin_id'].astype(str)\n",
    "    test_data['gender_id'] = test_data['gender_id'].astype(str)\n",
    "    test_data['district_id'] = test_data['district_id'].astype(str)\n",
    "\n",
    "    for age_bin in train_data['age_bin_id'].unique():\n",
    "        for gender in train_data['gender_id'].unique():\n",
    "            for district in train_data['district_id'].unique():\n",
    "                mask = (train_data['age_bin_id'] == age_bin) & (train_data['gender_id'] == gender) & (train_data['district_id'] == district)\n",
    "                count_75 = train_data.loc[mask & (train_data['as_of_date_id'] == 75), 'count'].values\n",
    "                count_77 = train_data.loc[mask & (train_data['as_of_date_id'] == 77), 'count'].values\n",
    "                if len(count_75) > 0 and len(count_77) > 0:\n",
    "                    avg_count = (count_75[0] + count_77[0]) / 2\n",
    "                    train_data.loc[mask & (train_data['as_of_date_id'] == 76), 'count'] = avg_count\n",
    "\n",
    "    # Filter train_data to start from as_of_date_id 70\n",
    "    train_data = train_data[train_data['as_of_date_id'] >= 70].reset_index(drop=True)\n",
    "\n",
    "    # Assume start date and convert 'as_of_date_id' to datetime\n",
    "    start_date = pd.to_datetime('2000-01-01')\n",
    "    train_data['ds'] = start_date + pd.to_timedelta(train_data['as_of_date_id'], unit='D')\n",
    "    test_data['ds'] = start_date + pd.to_timedelta(test_data['as_of_date_id'], unit='D')\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Function to normalize data\n",
    "def normalize_data(df, column):\n",
    "    mean = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    df[column] = (df[column] - mean) / std\n",
    "    return mean, std\n",
    "\n",
    "# Function to denormalize data\n",
    "def denormalize_data(df, column, mean, std):\n",
    "    df[column] = df[column] * std + mean\n",
    "    return df\n",
    "\n",
    "# Function to train models using Prophet\n",
    "def train_models(train_data):\n",
    "    models = {}\n",
    "    unique_combinations = train_data[['district_id', 'age_bin_id', 'gender_id']].drop_duplicates()\n",
    "\n",
    "    for _, row in unique_combinations.iterrows():\n",
    "        district, age_bin, gender = row['district_id'], row['age_bin_id'], row['gender_id']\n",
    "        mask = (train_data['district_id'] == district) & (train_data['age_bin_id'] == age_bin) & (train_data['gender_id'] == gender)\n",
    "        subset_data = train_data[mask]\n",
    "\n",
    "        # Normalize the data\n",
    "        mean, std = normalize_data(subset_data, 'count')\n",
    "        \n",
    "        subset_data = subset_data.rename(columns={'ds': 'ds', 'count': 'y'})\n",
    "        model = Prophet(\n",
    "            yearly_seasonality='auto',              # Enable yearly seasonality | 'auto'\n",
    "            changepoint_prior_scale=0.1,         # Adjust to control trend flexibility | 0.1\n",
    "            seasonality_prior_scale=10,           # Adjust to control seasonality flexibility | 10\n",
    "            changepoint_range=0.85                 # Allow more flexibility for trend changes | 0.9\n",
    "        )\n",
    "        model.add_seasonality(\n",
    "            name='12-period',\n",
    "            period=12, \n",
    "            fourier_order=5\n",
    "        )\n",
    "\n",
    "\n",
    "        with suppress_logging():\n",
    "            model.fit(subset_data[['ds', 'y']])\n",
    "        \n",
    "        models[(district, age_bin, gender)] = (model, mean, std)\n",
    "    return models\n",
    "\n",
    "# Function to make predictions\n",
    "def make_predictions(models, test_data):\n",
    "    predictions = []\n",
    "\n",
    "    unique_combinations = test_data[['district_id', 'age_bin_id', 'gender_id']].drop_duplicates()\n",
    "\n",
    "    for _, row in unique_combinations.iterrows():\n",
    "        district, age_bin, gender = row['district_id'], row['age_bin_id'], row['gender_id']\n",
    "        model, mean, std = models[(district, age_bin, gender)]\n",
    "        mask_test = (test_data['district_id'] == district) & (test_data['age_bin_id'] == age_bin) & (test_data['gender_id'] == gender)\n",
    "        subset_test_data = test_data[mask_test]\n",
    "\n",
    "        future = subset_test_data[['ds']]\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        # Denormalize the predictions\n",
    "        forecast['yhat'] = forecast['yhat'] * std + mean\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "            subset_test_data['Prediction'] = forecast['yhat'].values\n",
    "            subset_test_data['Prediction'] = subset_test_data['Prediction'].iloc[::-1].values\n",
    "\n",
    "        predictions.append(subset_test_data[['ID', 'district_id', 'age_bin_id', 'gender_id', 'as_of_date_id', 'Prediction']])\n",
    "    \n",
    "    return pd.concat(predictions, ignore_index=True)\n",
    "\n",
    "# Function to plot results\n",
    "def plot_results(train_data, predictions):\n",
    "    train_plot_df = train_data.groupby('as_of_date_id')['count'].sum().reset_index()\n",
    "    fig_train = px.line(train_plot_df, x='as_of_date_id', y='count', title='Sum of Population per Period of Time (Training Data)', labels={'as_of_date_id': 'Time Period', 'count': 'Total Population'}, markers=True)\n",
    "    test_plot_df = predictions.groupby('as_of_date_id')['Prediction'].sum().reset_index()\n",
    "    fig_test = px.line(test_plot_df, x='as_of_date_id', y='Prediction', title='Sum of Population per Period of Time (Test Predictions)', labels={'as_of_date_id': 'Time Period', 'Prediction': 'Total Predicted Population'}, markers=True)\n",
    "    \n",
    "    # Change the color of the prediction line\n",
    "    fig_test.data[0].line.color = 'red'\n",
    "    \n",
    "    fig_train.add_trace(fig_test.data[0])\n",
    "    fig_train.update_layout(title='Population Count per Period of Time (Training Data and Test Predictions)', xaxis_title='Time Period', yaxis_title='Population Count', legend_title='Dataset')\n",
    "    fig_train.show()\n",
    "\n",
    "# Function to plot results for a specific combination\n",
    "def plot_individual_results(district, age_bin, gender):\n",
    "    train_subset = train_data[(train_data['district_id'] == district) & \n",
    "                              (train_data['age_bin_id'] == age_bin) & \n",
    "                              (train_data['gender_id'] == gender)]\n",
    "    \n",
    "    pred_subset = predictions[(predictions['district_id'] == district) & \n",
    "                              (predictions['age_bin_id'] == age_bin) & \n",
    "                              (predictions['gender_id'] == gender)]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add training data\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=train_subset['as_of_date_id'], \n",
    "        y=train_subset['count'], \n",
    "        mode='lines+markers', \n",
    "        name='Training Data',\n",
    "        line=dict(color='blue')\n",
    "    ))\n",
    "    \n",
    "    # Add prediction data\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pred_subset['as_of_date_id'], \n",
    "        y=pred_subset['Prediction'], \n",
    "        mode='lines+markers', \n",
    "        name='Predictions',\n",
    "        line=dict(color='red')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'Population Count per Period of Time (District: {district}, Age Bin: {age_bin}, Gender: {gender})',\n",
    "        xaxis_title='Time Period',\n",
    "        yaxis_title='Population Count',\n",
    "        legend_title='Dataset'\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading data/training model/predicting/plotting general overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "train_file_path = '/workspaces/mpo-ab-test-overview/hacketon/data/train.csv'\n",
    "test_file_path = '/workspaces/mpo-ab-test-overview/hacketon/data/test.csv'\n",
    "\n",
    "# Load and preprocess data\n",
    "train_data, test_data = load_and_preprocess(train_file_path, test_file_path)\n",
    "\n",
    "# Train models for each combination of district, age_bin, and gender using Prophet\n",
    "models = train_models(train_data)\n",
    "\n",
    "# Make predictions using the trained models\n",
    "predictions = make_predictions(models, test_data)\n",
    "\n",
    "# Plot combined results with different color for predictions\n",
    "plot_results(train_data, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting overview case by case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dropdown for each combination to view individual plots\n",
    "unique_combinations = train_data[['district_id', 'age_bin_id', 'gender_id']].drop_duplicates()\n",
    "\n",
    "# Convert district_id to integers for correct sorting, then sort by district_id, age_bin_id, and gender_id\n",
    "unique_combinations['district_id_int'] = unique_combinations['district_id'].astype(int)\n",
    "unique_combinations = unique_combinations.sort_values(by=['district_id_int', 'age_bin_id', 'gender_id'])\n",
    "\n",
    "# Create the options for the dropdown\n",
    "options = [(f'District: {row[\"district_id\"]}, Age Bin: {row[\"age_bin_id\"]}, Gender: {row[\"gender_id\"]}', \n",
    "            (row[\"district_id\"], row[\"age_bin_id\"], row[\"gender_id\"])) for _, row in unique_combinations.iterrows()]\n",
    "\n",
    "# Drop the temporary integer column\n",
    "unique_combinations = unique_combinations.drop(columns=['district_id_int'])\n",
    "\n",
    "\n",
    "# Initialize the figure widget\n",
    "fig = go.FigureWidget()\n",
    "\n",
    "def update_plot(change):\n",
    "    district, age_bin, gender = change['new']\n",
    "    new_fig = plot_individual_results(district, age_bin, gender)\n",
    "    \n",
    "    with fig.batch_update():\n",
    "        fig.data = []\n",
    "        for trace in new_fig.data:\n",
    "            fig.add_trace(trace)\n",
    "        fig.layout = new_fig.layout\n",
    "\n",
    "# Create the dropdown widget\n",
    "dropdown = Dropdown(options=options, description='Select Group:')\n",
    "dropdown.observe(update_plot, names='value')\n",
    "\n",
    "# Create 'Back' and 'Next' buttons\n",
    "back_button = Button(description='Back')\n",
    "next_button = Button(description='Next')\n",
    "\n",
    "# Function to handle 'Back' button click\n",
    "def on_back_button_clicked(b):\n",
    "    current_index = [i[1] for i in options].index(dropdown.value)\n",
    "    if current_index > 0:\n",
    "        dropdown.value = options[current_index - 1][1]\n",
    "\n",
    "# Function to handle 'Next' button click\n",
    "def on_next_button_clicked(b):\n",
    "    current_index = [i[1] for i in options].index(dropdown.value)\n",
    "    if current_index < len(options) - 1:\n",
    "        dropdown.value = options[current_index + 1][1]\n",
    "\n",
    "back_button.on_click(on_back_button_clicked)\n",
    "next_button.on_click(on_next_button_clicked)\n",
    "\n",
    "# Display the dropdown, buttons, and the plot output\n",
    "display(VBox([HBox([back_button, next_button, dropdown]), fig]))\n",
    "\n",
    "# Initialize with the first combination\n",
    "dropdown.value = options[0][1]\n",
    "update_plot({'new': options[0][1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to 'output.csv'\n",
    "output = predictions[['ID', 'Prediction']].rename(columns={'Prediction': 'count'}).sort_values(by='ID')\n",
    "output.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
